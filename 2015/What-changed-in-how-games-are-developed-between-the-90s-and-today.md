# What changed in how games are developed between the ’90s and today?

	author: Steve Theodore
	written: 2015-02-27
	views: 2111
	upvotes: 10
	quora url: /What-changed-in-how-games-are-developed-between-the-’90s-and-today/answer/Steve-Theodore
	author url: /profile/Steve-Theodore


I'm not sure I buy the premise. For reasons that will become obvious, I think the hand-holdy 'cinematic' game is the exception, rather than the rule today. Big AAA blockbusters are an eye-catching, well-marketed exception, but they aren't the only game in games.

In terms of _development_ , it's all down to three things. In ascending order of importance:


Different kinds of complexity. In the old days most everything was hand-built, jury-rigged and one-of-a-kind. Radically different technologies existed side by side: raytracing and forward graphics, different kinds of AIs, hand-made systems for sound and physics... This tended to put highly technical devs in the drivers seat: the heroes of late '90's development, like Carmack and Tim Sweeney, were people who could create the systems that set games apart in a technical manner. However this also limited the kinds of things that could be attempted by game teams: innovating in story, character or art style added a lot of risk to the huge level or technical risk that any game faced in the days of DIY development.

Nowadays huge areas of game tech are cookie-cutter; physics, sound, and rendering engines are all available off the shelf. It's definitely not a trivial job to harmonize all the bits and pieces of tech that go to make a given game -- but the starting point is way, way higher than it used to be. A well done semi-pro game in Unity in 2015 generally has better graphics, sound, and physics than the best games of the Xbox - PS2 era: nobody will be impressed these days just because you've got normal maps, breakable crates, or footstep sounds! This is tough on professional devs because technical expertise is less of a barrier to entry than it used to be. It's awesome for the artform, though.

 Different scale. Modern game teams are bigger -- way, way bigger -- than game teams of the nineties. I think we were just under 30 people on _Half-Life_ in 1997. Destiny had as many as 700 people (and it started 7 years before it shipped. However it did not have anything like 700 people most of those years!) 

The shift to big teams is brought on primarily by the arms race for production values. _Half-Life_ characters had maybe 800 polys and a single 8-bit texture; as an artists, you could create a professional quality character model in 8 or 10 working days. Nowadays a finished character can consume months of time from multiple specialists: from the sculptor detailing out the pores and wrinkles on the characters face to the shader artists deciding how much melanin and subsurface scattering goes into the skin or how visible the corneal bump in the eyes is to the person building costumes using cloth patterns in [Marvelous Designer](http://www.marvelousdesigner.com/), creating game content is vastly more complex, laborious, and expensive than it used to be. 

This has big impacts on the way games are made: when you are borrowing a couple of million dollars to make a game, you can be happily profitable if you sell a few hundred thousand copies at $20 a box. On the other hand if the development costs $60-80 million (for a typical mid-range console game) or -- God forbid -- the $300-500 million budgets you see in _Gta V_ or _Destiny ...._ well, you develop a different attitude toward risk taking. Moreover, pushing a team of 300 or more people along any creative direction is very hard -- it's hard to hire that many people with similar tastes, skills and outlooks and the bureaucracy and management overhead of a big team is staggering. I once asked Isamu Kamikokuryo, the art director on _Final Fantasy XIII,_  which at one point had 800 people, what it took to be art director on such a famous franchise. He thought it over for a minute and said. "Must be tough. Very tough guy. 800 people: no way to make them all do what you want".

There's a bottom end. While $100 million plus games with movie tie ins and huge teams earn a lot of critical attention and mind share, the biggest change in games since the 90s is the rise of the indiesphere -- all those scrappy little devs who do things ranging from _Papers Please_ to _Monument Valley_ to, God help us, _Flappy Bird._  The number of people with the desire, tools and technical skills to make games -- and the distribution channels to get them into people's hands -- is easily two orders of magnitude higher than it was when I started. 

This is definitely a best-of-times, worst-of-times situation (_note: RIP Leonard Nimoy_ ) For the art form, this is amazing: little shops and solo visionaries can take risks and push boundaries that the big lumbering AAA behemoths dare not. The sequel-itis and risk aversion of big budget shooters have a perfect foil in fast-and-furious indie development. For game makers, on the other hand it's a mixed bag: making a living in games today is a bit more like making a living in professional music: the lines between paid professionals and folks working on their own dime are very blurred, which has some real down sides for the game developers trying to pay the mortgage. The average indie developer made on $11,000 last year (and that counts the handful of mega-successes). Like starting a rock band or trying out for the NFL, going indie is at the insane end of the risk-reward spectrum.

